{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Earth2Studio - Continued\n",
    "\n",
    "In this notebook, we will look at an example on how to run a deterministic inference workflow that couples a prognostic model with a diagnostic model. After which, we will look at how we run an Ensemble Inference with a prognostic model with pertubation.\n",
    "\n",
    "#### Contents of the Notebook\n",
    "\n",
    "- [Running Diagnostic and Ensemble Inference with Earth2Studio](#Running-Diagnostic-and-Ensemble-Inference-with-Earth2Studio)\n",
    "    - [Running Diagnostic Inference](#Running-Diagnostic-Inference)\n",
    "    - [Execute the Workflow](#Execute-the-Workflow)\n",
    "    - [Post Processing](#Post-Processing)\n",
    "- [Important: Free up GPU Memory!](#Important:-Free-up-GPU-Memory!)\n",
    "- [Running Ensemble Inference](#Running-Ensemble-Inference)\n",
    "    - [Set Up](#Set-Up)\n",
    "    - [Execute the Workflow](#Execute-the-Workflow)\n",
    "    - [Post Processing](#Post-Processing)\n",
    "    \n",
    "#### Learning Outcomes\n",
    "\n",
    "- Select a perturbation method\n",
    "- Running the built in diagnostic workflow\n",
    "- Running a simple built in workflow for ensembling\n",
    "- Post-processing results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Diagnostic Inference\n",
    "\n",
    "This diagnostic model will predict a new\n",
    "atmospheric quantity from the predicted fields of the prognostic.\n",
    "<center><img src=\"images/diagnostic.png\" alt=\"Drawing\" style=\"center\"/></center>\n",
    "\n",
    "### **Set Up**\n",
    "For this example, we will use the built in diagnostic workflow `earth2studio.run.diagnostic` method. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last notebook we looked at the list of models, datasources and IO Backend. Let us look at the list of Diagnostic Models available in Earth2Studio. \n",
    "\n",
    "**Diagnostic models**: \n",
    "Diagnostic models are a class of models that do not perform time-integration. These may be used to map between weather/climate variables to other quantities of interest, used to enbable additional analysis, improve prediction accuracy, downscale, etc.\n",
    "\n",
    "The list of Diagnostic Models available as of `0.7.0` are:\n",
    "\n",
    "- **models.dx.CorrDiffTaiwan** : CorrDiff is a Corrector Diffusion model that learns mappings between low- and high-resolution weather data with high fidelity.\n",
    "- **models.dx.ClimateNet** : Climate Net diagnostic model, built into Earth2Studio.\n",
    "- **models.dx.DerivedRH** : Calculates the relative humidity (RH) from specific humidity and temperature for specified pressure levels.\n",
    "- **models.dx.DerivedRHDewpoint** : Calculates the surface relative humidity (RH) from dewpoint temperature and air temperature.\n",
    "- **models.dx.DerivedVPD** : Calculates the Vapor Pressure Deficit (VPD) in hPa from relative humidity and temperature fields.\n",
    "- **models.dx.DerivedWS** : Calculates the Wind Speed (WS) magnitude from eastward and northward wind components for specified levels.\n",
    "- **models.dx.PrecipitationAFNO** : Precipitation AFNO diagnsotic model.\n",
    "- **models.dx.PrecipitationAFNOv2** : Improved Precipitation AFNO diagnostic model.\n",
    "- **models.dx.TCTrackerWuDuan** : Finds a list of tropical cyclone (TC) centers using an adaption of the method described in the conditions in Wu and Duan 2023.\n",
    "- **models.dx.TCTrackerVitart** : Finds a list of tropical cyclone centers using the conditions in Vitart 1997\n",
    "- **models.dx.WindgustAFNO** : Wind gust AFNO diagnsotic model.\n",
    "- **models.dx.Identity** :  Identity diagnostic that is coordinate insensitive.\n",
    "\n",
    "For this example, we will be using the following:\n",
    "\n",
    "- **Prognostic Model**: Use the built in FourCastNet Model :py:class:`earth2studio.models.px.FCN`.\n",
    "- **Diagnostic Model**: Use the built in precipitation AFNO model :py:class:`earth2studio.models.dx.PrecipitationAFNO`.\n",
    "- **Datasource**: Pull data from the GFS data api :py:class:`earth2studio.data.GFS`.\n",
    "- **IO Backend**: Save the outputs into a Zarr store :py:class:`earth2studio.io.ZarrBackend`.\n",
    "\n",
    "#### Precipitation AFNO Model: \n",
    "\n",
    "The Precipitation AFNO is FourCastNet diagnostic model which predicts total precipitation from 20 atmospheric variables. The total precipitation, sourced from the ERA5 re-analysis dataset, represents the accumulated liquid and frozen water that falls to the Earthâ€™s surface through rainfall and snow. It is defined in units of length as the depth of water that would accumulate if spread evenly over a unit grid box of the model. Here is a visual representation of how we would implement the Diagnostic inference. \n",
    "\n",
    "<center><img src=\"images/precipafno.png\" alt=\"Drawing\" style=\"center\" width=\"600px\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from earth2studio.data import GFS\n",
    "from earth2studio.io import ZarrBackend\n",
    "from earth2studio.models.dx import PrecipitationAFNO\n",
    "from earth2studio.models.px import FCN\n",
    "\n",
    "# Prognostic Model - Load the default model package which downloads the check point from NGC\n",
    "package = FCN.load_default_package()\n",
    "prognostic_model = FCN.load_model(package)\n",
    "\n",
    "# Diagnostic Model - Load the default model package which downloads the check point from NGC\n",
    "package = PrecipitationAFNO.load_default_package()\n",
    "diagnostic_model = PrecipitationAFNO.load_model(package)\n",
    "\n",
    "# Data Source - Create the data source\n",
    "data = GFS()\n",
    "\n",
    "# IO Backend - Create the IO handler, store in memory\n",
    "io = ZarrBackend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the Workflow\n",
    "With all components initialized, running the workflow is a single line of Python code.\n",
    "Workflow will return the provided IO object back to the user, which can be used to\n",
    "then post process. Let us look at the API for Diagnostic inference\n",
    "\n",
    "```python\n",
    "def diagnostic(\n",
    "    time: list[str] | list[datetime] | list[np.datetime64],\n",
    "    nsteps: int,\n",
    "    prognostic: PrognosticModel,\n",
    "    diagnostic: DiagnosticModel,\n",
    "    data: DataSource,\n",
    "    io: IOBackend,\n",
    "    output_coords: CoordSystem = OrderedDict({}),\n",
    "    device: torch.device | None = None,\n",
    ") -> IOBackend:\n",
    "    \"\"\"Built in diagnostic workflow.\n",
    "    This workflow creates a determinstic inference pipeline that couples a prognostic\n",
    "    model with a diagnostic model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time : list[str] | list[datetime] | list[np.datetime64]\n",
    "        List of string, datetimes or np.datetime64\n",
    "    nsteps : int\n",
    "        Number of forecast steps\n",
    "    prognostic : PrognosticModel\n",
    "        Prognostic model\n",
    "    diagnostic: DiagnosticModel\n",
    "        Diagnostic model, must be on same coordinate axis as prognostic\n",
    "    data : DataSource\n",
    "        Data source\n",
    "    io : IOBackend\n",
    "        IO object\n",
    "    output_coords: CoordSystem, optional\n",
    "        IO output coordinate system override, by default OrderedDict({})\n",
    "    device : torch.device, optional\n",
    "        Device to run inference on, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    IOBackend\n",
    "        Output IO object\n",
    "    \"\"\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import earth2studio.run as run\n",
    "\n",
    "nsteps = 8\n",
    "io = run.diagnostic(\n",
    "    [\"2021-06-01\"], nsteps, prognostic_model, diagnostic_model, data, io\n",
    ")\n",
    "\n",
    "print(io.root.tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing\n",
    "The last step is to plot the resulting predicted total precipitation. The power of\n",
    "diagnostic models is that they allow the prediction of any variable from a pre-trained\n",
    "prognostic model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "forecast = datetime(2021, 6, 1)\n",
    "variable = \"tp\"\n",
    "step = 8  # lead time = 48 hrs\n",
    "\n",
    "plt.close(\"all\")\n",
    "# Create a Orthographic projection of USA\n",
    "projection = ccrs.Orthographic(-100, 40)\n",
    "\n",
    "# Create a figure and axes with the specified projection\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": projection}, figsize=(10, 6))\n",
    "\n",
    "# Plot the field using pcolormesh\n",
    "levels = np.arange(0.0, 0.01, 0.001)\n",
    "im = ax.contourf(\n",
    "    io[\"lon\"][:],\n",
    "    io[\"lat\"][:],\n",
    "    io[variable][0, step],\n",
    "    levels,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    vmax=0.01,\n",
    "    vmin=0.00,\n",
    "    cmap=\"terrain\",\n",
    ")\n",
    "\n",
    "# Set title\n",
    "ax.set_title(f\"{forecast.strftime('%Y-%m-%d')} - Lead time: {6*step}hrs\")\n",
    "\n",
    "# Add coastlines and gridlines6\n",
    "ax.set_extent([220, 340, 20, 70])  # [lat min, lat max, lon min, lon max]\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "plt.colorbar(\n",
    "    im, ax=ax, ticks=levels, shrink=0.75, pad=0.04, label=\"Total precipitation (m)\"\n",
    ")\n",
    "\n",
    "plt.savefig(\"outputs/02_tp_prediction.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now clean up the GPU memory and look at another inbuilt workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important: Free up GPU Memory!\n",
    "\n",
    "Run the below cell to free up GPU memory after training the model before moving to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Ensemble Inference\n",
    "\n",
    "<center><img src=\"images/ensemble.png\" alt=\"Drawing\" style=\"center\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "All workflows inside Earth2Studio require constructed components to be\n",
    "handed to them. In this example, we will use the built in ensemble workflow\n",
    " `earth2studio.run.ensemble`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensemble Inference**: Ensemble inference with perturbation in weather forecasting involves generating multiple forecasts with slight variations in initial conditions or model parameters. This approach is crucial because the atmosphere is a chaotic system where small changes in initial conditions can lead to significant differences in outcomes. By using ensemble methods, we can quantify the uncertainty in predictions and provide a range of possible weather scenarios, enhancing the reliability and accuracy of forecasts, especially for extreme weather events. This method is particularly useful in deep learning models, which traditionally focus on deterministic outputs, by allowing them to incorporate probabilistic elements and better reflect the inherent uncertainties in weather prediction.\n",
    "\n",
    "As we understand the use of Ensemble inference, we will use Pertubation to add changes to initial conditions to this flow. Some of the Pertubation methods available in version `0.7.0` are as follows: \n",
    "\n",
    "- **perturbation.Brown** : Lat/Lon 2D brown noise\n",
    "- **perturbation.BredVector** : Bred Vector perturbation method, a classical technique for pertubations in ensemble forecasting.\n",
    "- **perturbation.CorrelatedSphericalGaussian** : Produces Gaussian random field on the sphere with Matern covariance peturbation method output to a lat lon grid\n",
    "- **perturbation.Gaussian** : Standard Gaussian peturbation\n",
    "- **perturbation.HemisphericCentredBredVector** : Bred Vector perturbation method, following the approach introduced in 'Huge Ensembles Part I: Design of Ensemble Weather Forecasts using Spherical Fourier Neural Operators'.\n",
    "- **perturbation.LaggedEnsemble** : Lagged Ensemble perturbation method.\n",
    "- **perturbation.SphericalGaussian** : Gaussian random field on the sphere with Matern covariance peturbation method output to a lat lon grid\n",
    "- **perturbation.Zero** : No perturbation scheme\n",
    "\n",
    "We will use the following:\n",
    "\n",
    "- **Prognostic Model**: Use the built in FourCastNet model `earth2studio.models.px.FCN`.\n",
    "- **perturbation_method**: Use the Spherical Gaussian Method `earth2studio.perturbation.SphericalGaussian`.\n",
    "- **Datasource**: Pull data from the GFS data api `earth2studio.data.GFS`.\n",
    "- **IO Backend**: Save the outputs into a Zarr store `earth2studio.io.ZarrBackend`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from earth2studio.data import GFS\n",
    "from earth2studio.io import ZarrBackend\n",
    "from earth2studio.models.px import FCN\n",
    "from earth2studio.perturbation import SphericalGaussian\n",
    "from earth2studio.run import ensemble\n",
    "\n",
    "# # Prognostic Model - Load the default model package which downloads the check point from NGC\n",
    "package = FCN.load_default_package()\n",
    "model = FCN.load_model(package)\n",
    "\n",
    "# Pertubation Method - Instantiate the pertubation method\n",
    "sg = SphericalGaussian(noise_amplitude=0.15)\n",
    "\n",
    "# Data Source - Create the data source\n",
    "data = GFS()\n",
    "\n",
    "# IO Backend - Create the IO handler, store in memory\n",
    "chunks = {\"ensemble\": 1, \"time\": 1}\n",
    "io = ZarrBackend(file_name=\"outputs/02_ensemble_sg.zarr\", chunks=chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the Workflow\n",
    "With all components initialized, running the workflow is a single line of Python code.\n",
    "Workflow will return the provided IO object back to the user, which can be used to\n",
    "then post process. Let us look at the API for Ensemble: \n",
    "\n",
    "```python\n",
    "\n",
    "def ensemble(\n",
    "    time: list[str] | list[datetime] | list[np.datetime64],\n",
    "    nsteps: int,\n",
    "    nensemble: int,\n",
    "    prognostic: PrognosticModel,\n",
    "    data: DataSource,\n",
    "    io: IOBackend,\n",
    "    perturbation: Perturbation,\n",
    "    batch_size: int | None = None,\n",
    "    output_coords: CoordSystem = OrderedDict({}),\n",
    "    device: torch.device | None = None,\n",
    ") -> IOBackend:\n",
    "    \"\"\"Built in ensemble workflow.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time : list[str] | list[datetime] | list[np.datetime64]\n",
    "        List of string, datetimes or np.datetime64\n",
    "    nsteps : int\n",
    "        Number of forecast steps\n",
    "    nensemble : int\n",
    "        Number of ensemble members to run inference for.\n",
    "    prognostic : PrognosticModel\n",
    "        Prognostic models\n",
    "    data : DataSource\n",
    "        Data source\n",
    "    io : IOBackend\n",
    "        IO object\n",
    "    perturbation_method : Perturbation\n",
    "        Method to perturb the initial condition to create an ensemble.\n",
    "    batch_size: int, optional\n",
    "        Number of ensemble members to run in a single batch,\n",
    "        by default None.\n",
    "    output_coords: CoordSystem, optional\n",
    "        IO output coordinate system override, by default OrderedDict({})\n",
    "    device : torch.device, optional\n",
    "        Device to run inference on, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    IOBackend\n",
    "        Output IO object\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "For the forecast we will predict for 10 steps (for FCN, this is 60 hours) with 8 ensemble\n",
    "members which will be ran in 2 batches with batch size 4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "nsteps = 10\n",
    "nensemble = 8\n",
    "batch_size = 2\n",
    "io = ensemble(\n",
    "    [\"2024-01-01\"],\n",
    "    nsteps,\n",
    "    nensemble,\n",
    "    model,\n",
    "    data,\n",
    "    io,\n",
    "    sg,\n",
    "    batch_size=batch_size,\n",
    "    output_coords={\"variable\": np.array([\"t2m\", \"tcwv\"])},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing\n",
    "The last step is to post process our results. Cartopy is a great library for plotting\n",
    "fields on projections of a sphere.\n",
    "\n",
    "Notice that the Zarr IO function has additional APIs to interact with the stored data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "forecast = \"2024-01-01\"\n",
    "\n",
    "\n",
    "def plot_(axi, data, title, cmap):\n",
    "    \"\"\"Convenience function for plotting pcolormesh.\"\"\"\n",
    "    # Plot the field using pcolormesh\n",
    "    im = axi.pcolormesh(\n",
    "        io[\"lon\"][:],\n",
    "        io[\"lat\"][:],\n",
    "        data,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        cmap=cmap,\n",
    "    )\n",
    "    plt.colorbar(im, ax=axi, shrink=0.6, pad=0.04)\n",
    "    # Set title\n",
    "    axi.set_title(title)\n",
    "    # Add coastlines and gridlines\n",
    "    axi.coastlines()\n",
    "    axi.gridlines()\n",
    "\n",
    "\n",
    "for variable, cmap in zip([\"tcwv\"], [\"Blues\"]):\n",
    "    step = 4  # lead time = 24 hrs\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    # Create a Robinson projection\n",
    "    projection = ccrs.Robinson()\n",
    "\n",
    "    # Create a figure and axes with the specified projection\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(\n",
    "        nrows=1, ncols=3, subplot_kw={\"projection\": projection}, figsize=(16, 3)\n",
    "    )\n",
    "\n",
    "    plot_(\n",
    "        ax1,\n",
    "        io[variable][0, 0, step],\n",
    "        f\"{forecast} - Lead time: {6*step}hrs - Member: {0}\",\n",
    "        cmap,\n",
    "    )\n",
    "    plot_(\n",
    "        ax2,\n",
    "        io[variable][1, 0, step],\n",
    "        f\"{forecast} - Lead time: {6*step}hrs - Member: {1}\",\n",
    "        cmap,\n",
    "    )\n",
    "    plot_(\n",
    "        ax3,\n",
    "        np.std(io[variable][:, 0, step], axis=0),\n",
    "        f\"{forecast} - Lead time: {6*step}hrs - Std\",\n",
    "        cmap,\n",
    "    )\n",
    "\n",
    "    plt.savefig(f\"outputs/03_{forecast}_{variable}_{step}_ensemble.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have looked at three workflows with Earth2Studio, but Earth2Studio allows us to work on our custom worklflows, whcih gives flexibility to researchers to expand on them. Here are some resrouces for Earth2Studio: \n",
    "\n",
    "- [Earth2Studio Github](https://github.com/NVIDIA/earth2studio)\n",
    "- [Documentation](https://nvidia.github.io/earth2studio/index.html)\n",
    "- [API Reference](https://nvidia.github.io/earth2studio/modules/index.html)\n",
    "- [Additional Examples](https://nvidia.github.io/earth2studio/examples/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "Don't forget to check out additional [Open Hackathons Resources](https://www.openhackathons.org/s/technical-resources) and join our [OpenACC and Hackathons Slack Channel](https://www.openacc.org/community#slack) to share your experience and get more help from the community.\n",
    "\n",
    "---\n",
    "\n",
    "# Licensing\n",
    "\n",
    "Copyright Â© 2023 OpenACC-Standard.org.  This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials may include references to hardware and software developed by other entities; all applicable licensing and copyrights apply.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
